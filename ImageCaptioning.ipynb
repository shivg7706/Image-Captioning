{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCaptioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivg7706/Image-Captioning/blob/master/ImageCaptioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R271uW0RzXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4aea958d-fcfc-469b-dc99-a211d628f424"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSgOJ9iRO6TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./drive/My\\ Drive/Flickr8k_text.zip ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juAC7Kz4O7aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_Dataset.zip\n",
        "# !unzip Flickr8k_text.zip\n",
        "!rm -rf Flickr8k_Dataset.zip\n",
        "# !rm -rf Flickr8k_text.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZPbjeJTO76c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "captions = open('Flickr8k.token.txt', 'r').read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LngmP9hOO73M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY8TLg3NO7z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "for caption in captions:\n",
        "    caption = caption.split('\\t')\n",
        "    caption[0] = caption[0][:len(caption[0])-2]\n",
        "    if caption[0] in d:\n",
        "        d[caption[0]].append(caption[1])\n",
        "    else:\n",
        "        d[caption[0]] = [caption[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOASCzA6O7tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQI1G8sO7ip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08e831b0-9bcc-4484-af9b-be80f0b65369"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjiKzOix37o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('Flickr_8k.trainImages.txt', 'r') as f:\n",
        "    train_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4YWsNAKzxRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Flickr_8k.devImages.txt', 'r') as f:\n",
        "    val_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0FwxcX06tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Flickr_8k.testImages.txt', 'r') as f:\n",
        "    test_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFfh9Uyb3VYk",
        "colab_type": "code",
        "outputId": "3b9d34e6-37aa-441e-fb10-b2038cf4068a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "vgg = VGG16(weights='imagenet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 06:45:21.558927 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 06:45:21.589104 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 06:45:21.596650 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0717 06:45:21.635268 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0717 06:45:25.422724 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0717 06:45:25.424000 139721509341056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCj69pe04Y7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "inputs = vgg.input\n",
        "output = vgg.layers[-2].output\n",
        "\n",
        "model1 = Model(inputs, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNoJ24iE4_3a",
        "colab_type": "code",
        "outputId": "fa989822-3406-46da-a52d-dcb146e7b22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTiK8qKl5BbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(image):\n",
        "    img = load_img('{}'.format(image), target_size=(224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    \n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsHTaWkA5jo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoding_images(image):\n",
        "    img = preprocessing(image)\n",
        "    pred = model1.predict(img)\n",
        "    pred = pred.reshape(4096)\n",
        "    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaf0Jdn78DDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5eALLYb6HCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_encode = {}\n",
        "\n",
        "for image in train_images:\n",
        "    train_encode[image] = get_encoding_images(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3lPqSfu6dK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_encode = {}\n",
        "\n",
        "for image in val_images:\n",
        "    val_encode[image] = get_encoding_images(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO_DCAU28-SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = {}\n",
        "for i in train_images:\n",
        "    train_text[i] = d[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9pr-dmP9hm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_text = {}\n",
        "for i in val_images:\n",
        "    val_text[i] = d[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlNtYJu-RdI",
        "colab_type": "text"
      },
      "source": [
        "#### Adding _start_ and _end_ to each sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPaNINOP-O6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bhaji = []\n",
        "for sublist in train_text.values():\n",
        "    for sen in sublist:\n",
        "        bhaji.append('<start> {} <end>'.format(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28mVhLMSixTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = max([len(sen.split()) for sen in bhaji])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgvXdor6a2q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(bhaji)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73TNXYUKrtgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7aAqJgua3EX",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BDPrr9mMmPWC",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Dropout, RepeatVector, add, Embedding, LSTM, Bidirectional, BatchNormalization, TimeDistributed\n",
        "                       \n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "def cmodel():\n",
        "    \n",
        "    input_1 = Input((4096,))\n",
        "    x = Dropout(0.2)(input_1)\n",
        "    output_1 = Dense(300, activation='relu')(x)\n",
        "    \n",
        "\n",
        "    input_2 = Input((max_length,))\n",
        "    x = Embedding(vocab_size, 300, mask_zero=True)(input_2)\n",
        "    output_2 = LSTM(300)(x)\n",
        "    \n",
        "    x = add([output_1, output_2])\n",
        "    x = Dense(300, activation='relu')(x)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[input_1, input_2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    plot_model(model, show_shapes=True, to_file='model.png')\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6JmhoRtqYOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmodel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySCmeDOvmQcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_v2():\n",
        "    input_1 = Input((4096,))\n",
        "    x = Dense(256, activation='relu')(input_1)\n",
        "    output_1 = RepeatVector(max_length)(x)\n",
        "\n",
        "\n",
        "    input_2 = Input((max_length,))\n",
        "    x = Embedding(vocab_size, 256)(input_2)\n",
        "    x = LSTM(256,return_sequences=True)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    output_2 = TimeDistributed(Dense(256))(x)\n",
        "\n",
        "\n",
        "    \n",
        "    x = add([output_1, output_2])\n",
        "    \n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Bidirectional(LSTM(500,return_sequences=False))(x)\n",
        "\n",
        "    outputs = Dense(vocab_size, activation='softmax')(x)\n",
        "    \n",
        "    model = Model([input_1, input_2], outputs)\n",
        "    print(model.summary())\n",
        "    plot_model(model, show_shapes=True, to_file='model.png')\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFJtUTMa7Za",
        "colab_type": "code",
        "outputId": "b0c90fd8-f1fa-4c74-df34-9444ed5500b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "model = model_v2()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 40)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 40, 256)      1888256     input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 40, 256)      525312      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 4096)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 40, 256)      0           lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 256)          1048832     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 40, 256)      1024        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_4 (RepeatVector)  (None, 40, 256)      0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 40, 256)      65792       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 40, 256)      0           repeat_vector_4[0][0]            \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 40, 256)      0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 40, 256)      1024        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 1000)         3028000     batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 7376)         7383376     bidirectional_6[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 13,941,616\n",
            "Trainable params: 13,940,592\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjNS-nBrPCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def create_sequences(captions_list, image):\n",
        "    \n",
        "    X1, X2, y = [], [], []\n",
        "    for caption in captions_list:\n",
        "        \n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "        for i in range(1, len(seq)):\n",
        "            \n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            \n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            \n",
        "            out_seq = to_categorical([out_seq], vocab_size)[0]\n",
        "            \n",
        "            X1.append(image)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    \n",
        "    return X1, X2, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezTQmqAnyFiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(batch_size):\n",
        "    \n",
        "    np.random.seed(34)\n",
        "    \n",
        "    image_ids = list(train_text.keys())\n",
        "    count = 0 \n",
        "    \n",
        "    while True:\n",
        "        if count >= len(image_ids):\n",
        "            count = 0\n",
        "        \n",
        "        # Batch list to store data\n",
        "        input_img_batch, input_sequence_batch, output_word_batch = [], [], []\n",
        "        for i in range(count, min(len(image_ids), count+batch_size)):\n",
        "            image_id = image_ids[i]\n",
        "            \n",
        "            image = train_encode[image_id]\n",
        "            captions_list = d[image_id]\n",
        "            \n",
        "            input_img, input_sequence, output_word = create_sequences(captions_list, image)\n",
        "            \n",
        "            for j in range(len(input_img)):\n",
        "                input_img_batch.append(input_img[j])\n",
        "                input_sequence_batch.append(input_sequence[j])\n",
        "                output_word_batch.append(output_word[j])\n",
        "#             \n",
        "        count = count + batch_size\n",
        "#         print(len(input_img_batch), len(input_sequence_batch), len(output_word_batch))\n",
        "        \n",
        "        \n",
        "        yield [[np.array(input_img_batch), np.array(input_sequence_batch)], np.array(output_word_batch)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOEd3KSuXUA",
        "colab_type": "code",
        "outputId": "3fd6c1ea-f321-4e62-e018-b958645e0c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "history = model.fit_generator(data_generator(32), epochs=10, steps_per_epoch=200)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 165s 825ms/step - loss: 4.8746 - acc: 0.1854\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 3.6175 - acc: 0.2939\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 3.1630 - acc: 0.3329\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 2.8329 - acc: 0.3637\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 159s 795ms/step - loss: 2.5721 - acc: 0.3954\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 159s 795ms/step - loss: 2.3768 - acc: 0.4249\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 2.2227 - acc: 0.4486\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 2.0987 - acc: 0.4686\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 159s 796ms/step - loss: 1.9887 - acc: 0.4877\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 159s 795ms/step - loss: 1.8865 - acc: 0.5071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpFOqIybu4Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('caption.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moxjk7Qpwos9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_caption(image):\n",
        "\n",
        "    in_text = '<start>'\n",
        "    image = image.reshape(1, 4096)\n",
        "    for _ in range(max_length):\n",
        "        \n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        \n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "#         print(sequence.shape)\n",
        "        yhat = model.predict([image, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        \n",
        "        word = int_to_word(yhat, tokenizer)\n",
        "        \n",
        "        if word is None:\n",
        "            break\n",
        "        \n",
        "        in_text += ' ' + word\n",
        "        \n",
        "        if word == '<end>':\n",
        "            break\n",
        "\n",
        "    return in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x00mzWKyClKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_word(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qURK1ye9iNF6",
        "colab_type": "code",
        "outputId": "9b75bc38-ccbc-4a7f-b558-9e468c7e3f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate_caption(get_encoding_images('test.jpg')))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> a girl in a white shirt and jeans is sitting on a park bench with her hands on her head and her hand to her left arm to her left arm to her left the sun in the background of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MldeK_QwmUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./caption.h5 ./drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSWQog1fyaMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}