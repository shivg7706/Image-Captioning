{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCaptioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivg7706/Image-Captioning/blob/master/ImageCaptioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R271uW0RzXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSgOJ9iRO6TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./drive/My\\ Drive/Flickr8k_text.zip ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juAC7Kz4O7aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "# !unzip Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_text.zip\n",
        "# !rm -rf Flickr8k_Dataset.zip\n",
        "!rm -rf Flickr8k_text.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZPbjeJTO76c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "captions = open('Flickr8k.token.txt', 'r').read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LngmP9hOO73M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY8TLg3NO7z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "for caption in captions:\n",
        "    caption = caption.split('\\t')\n",
        "    caption[0] = caption[0][:len(caption[0])-2]\n",
        "    if caption[0] in d:\n",
        "        d[caption[0]].append(caption[1])\n",
        "    else:\n",
        "        d[caption[0]] = [caption[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOASCzA6O7tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQI1G8sO7ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjiKzOix37o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('Flickr_8k.trainImages.txt', 'r') as f:\n",
        "    train_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4YWsNAKzxRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Flickr_8k.devImages.txt', 'r') as f:\n",
        "    val_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0FwxcX06tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Flickr_8k.testImages.txt', 'r') as f:\n",
        "    test_images = f.read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFfh9Uyb3VYk",
        "colab_type": "code",
        "outputId": "65421926-7be1-475c-ed12-9ec6f5a136a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "vgg = VGG16(weights='imagenet')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0716 08:03:25.553755 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0716 08:03:25.585803 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0716 08:03:25.593883 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0716 08:03:25.642839 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0716 08:03:29.702780 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0716 08:03:29.704246 140129198180224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCj69pe04Y7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "inputs = vgg.input\n",
        "output = vgg.layers[-2].output\n",
        "\n",
        "model = Model(inputs, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNoJ24iE4_3a",
        "colab_type": "code",
        "outputId": "204dce73-cd56-4496-c69f-9f18982dd249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTiK8qKl5BbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(image):\n",
        "    img = load_img('{}'.format(image), target_size=(224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    \n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsHTaWkA5jo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoding_images(image):\n",
        "    img = preprocessing(image)\n",
        "    pred = model.predict(img)\n",
        "    pred = pred.reshape(4096)\n",
        "    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaf0Jdn78DDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5eALLYb6HCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_encode = {}\n",
        "\n",
        "for image in train_images:\n",
        "    train_encode[image] = get_encoding_images(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3lPqSfu6dK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_encode = {}\n",
        "\n",
        "for image in val_images:\n",
        "    val_encode[image] = get_encoding_images(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO_DCAU28-SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = {}\n",
        "for i in train_images:\n",
        "    train_text[i] = d[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9pr-dmP9hm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_text = {}\n",
        "for i in val_images:\n",
        "    val_text[i] = d[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlNtYJu-RdI",
        "colab_type": "text"
      },
      "source": [
        "#### Adding _start_ and _end_ to each sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPaNINOP-O6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bhaji = []\n",
        "for sublist in train_text.values():\n",
        "    for sen in sublist:\n",
        "        bhaji.append('<start> {} <end>'.format(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28mVhLMSixTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = max([len(sen.split()) for sen in bhaji])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnwE-XGV_EgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = []\n",
        "for sen in bhaji:\n",
        "    word += sen.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41gnagLR_GXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqABicrFAfRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CesoFS8jAt7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = {val:index for index, val in enumerate(words)}\n",
        "idx2word = {index:val for index, val in enumerate(words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIAYVmF4BPdy",
        "colab_type": "code",
        "outputId": "4ec50cbc-1947-4f30-f815-6a405cbc07ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idx2word[7706]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Twome'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0omhwDtBU5z",
        "colab_type": "code",
        "outputId": "07e79ce8-7087-4668-e96e-ec83c0fdac56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2idx['brightly-lit']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgvXdor6a2q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(bhaji)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73TNXYUKrtgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7aAqJgua3EX",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egBSH1cgCsYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Dropout, RepeatVector, add, Embedding, LSTM\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "def cmodel():\n",
        "    \n",
        "    input_1 = Input((4096,))\n",
        "    x = Dropout(0.2)(input_1)\n",
        "    output_1 = Dense(300, activation='relu')(x)\n",
        "    \n",
        "\n",
        "    input_2 = Input((max_length,))\n",
        "    x = Embedding(vocab_size, 300, mask_zero=True)(input_2)\n",
        "    output_2 = LSTM(300)(x)\n",
        "    \n",
        "    x = add([output_1, output_2])\n",
        "    x = Dense(300, activation='relu')(x)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[input_1, input_2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    plot_model(model, show_shapes=True, to_file='model.png')\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFJtUTMa7Za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "7a8e324d-a870-43bd-c1df-b1008e537c5b"
      },
      "source": [
        "model = cmodel()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 4096)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 40)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 4096)         0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 40, 300)      2212800     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 300)          1229100     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 300)          721200      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 300)          0           dense_15[0][0]                   \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 300)          90300       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 7376)         2220176     dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 6,473,576\n",
            "Trainable params: 6,473,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjNS-nBrPCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def create_sequences(captions_list, image):\n",
        "    \n",
        "    X1, X2, y = [], [], []\n",
        "    for caption in captions_list:\n",
        "        \n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "        for i in range(1, len(seq)):\n",
        "            \n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            \n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            \n",
        "            out_seq = to_categorical([out_seq], vocab_size)[0]\n",
        "            \n",
        "            X1.append(image)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    \n",
        "    return X1, X2, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezTQmqAnyFiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(batch_size):\n",
        "    \n",
        "    np.random.seed(34)\n",
        "    \n",
        "    image_ids = list(train_text.keys())\n",
        "    count = 0 \n",
        "    \n",
        "    while True:\n",
        "        if count >= len(image_ids):\n",
        "            count = 0\n",
        "        \n",
        "        # Batch list to store data\n",
        "        input_img_batch, input_sequence_batch, output_word_batch = [], [], []\n",
        "        for i in range(count, min(len(image_ids), count+batch_size)):\n",
        "            image_id = image_ids[i]\n",
        "            \n",
        "            image = train_encode[image_id]\n",
        "            captions_list = d[image_id]\n",
        "            \n",
        "            input_img, input_sequence, output_word = create_sequences(captions_list, image)\n",
        "            \n",
        "            for j in range(len(input_img)):\n",
        "                input_img_batch.append(input_img[j])\n",
        "                input_sequence_batch.append(input_sequence[j])\n",
        "                output_word_batch.append(output_word[j])\n",
        "#             \n",
        "        count = count + batch_size\n",
        "#         print(len(input_img_batch), len(input_sequence_batch), len(output_word_batch))\n",
        "        \n",
        "        \n",
        "        yield [[np.array(input_img_batch), np.array(input_sequence_batch)], np.array(output_word_batch)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOEd3KSuXUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "769a56ce-ef05-45a5-efd5-48eb7ffd7147"
      },
      "source": [
        "history = model.fit_generator(data_generator(64), epochs=10, steps_per_epoch=500)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 213s 426ms/step - loss: 0.9771 - acc: 0.7086\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 213s 425ms/step - loss: 0.9251 - acc: 0.7209\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 212s 423ms/step - loss: 0.8672 - acc: 0.7367\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 212s 423ms/step - loss: 0.7955 - acc: 0.7574\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 212s 425ms/step - loss: 0.7602 - acc: 0.7654\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 211s 423ms/step - loss: 0.7312 - acc: 0.7727\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 211s 422ms/step - loss: 0.6725 - acc: 0.7907\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 211s 423ms/step - loss: 0.6238 - acc: 0.8056\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 211s 421ms/step - loss: 0.5958 - acc: 0.8137\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 211s 422ms/step - loss: 0.5816 - acc: 0.8166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpFOqIybu4Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('caption.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moxjk7Qpwos9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_caption(image):\n",
        "    \n",
        "    in_text = '<start>'\n",
        "    \n",
        "    for _ in range(max_length):\n",
        "        \n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        \n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        \n",
        "        yhat = model.predict([image, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        \n",
        "        word = int_to_word(yhat, tokenizer)\n",
        "        \n",
        "        if word is None:\n",
        "            break\n",
        "        \n",
        "        in_text += ' ' + word\n",
        "        \n",
        "        if word == '<end>':\n",
        "            break\n",
        "\n",
        "    return in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x00mzWKyClKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_word(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qURK1ye9iNF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "ecefb9b8-7329-4d33-a611-72d272c59c5d"
      },
      "source": [
        "print(generate_caption(get_encoding_images('IMG_20181013_112051.jpg')))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-992a5731a218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoding_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IMG_20181013_112051.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-9e11ce8e3ada>\u001b[0m in \u001b[0;36mget_encoding_images\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_encoding_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[-27.939003 , -29.779    , -22.68     ],\n         [-28.939003 , -29.779    , -24.68     ],\n         [-31.939003 , -32.779    , -27.68     ],\n         ...,\n         [ 11.060997 ,  30.221    ,..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taerg2HWjIzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}